{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import us\n",
    "sns.set(style='whitegrid', color_codes=True) \n",
    "from IPython.display import display\n",
    "import altair as alt\n",
    "from vega_datasets import data\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"cleaned_full_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Swing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_gop_16 = df[\"p_dem_16\"]\n",
    "p_dem_16 = df[\"p_gop_16\"]\n",
    "del df[\"p_dem_16\"]\n",
    "del df[\"p_gop_16\"]\n",
    "df[\"p_dem_16\"] = p_dem_16\n",
    "df[\"p_gop_16\"] = p_gop_16\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"c_dem\"] = df[\"p_dem_20\"] - df[\"p_dem_16\"]\n",
    "df[\"c_gop\"] = df[\"p_gop_20\"] - df[\"p_gop_16\"]\n",
    "df[\"swing_gop\"] = (df[\"c_gop\"]-df[\"c_dem\"])/2\n",
    "df[\"swing_dem\"] = (df[\"c_dem\"]-df[\"c_gop\"])/2\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging results/census data with Shape Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_map = gpd.read_file(\"county_shape/cb_2019_us_county_500k.shp\")\n",
    "us_map.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in us_map[\"AFFGEOID\"]:\n",
    "    if i not in list(df[\"geo_id\"]):\n",
    "        us_map = us_map[~us_map.AFFGEOID.str.contains(i)]\n",
    "len(us_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Moving Hawaii\n",
    "m = us_map.STATEFP == \"15\"\n",
    "us_map[m] = us_map[m].set_geometry(us_map[m].translate(54))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_map[\"geo_id\"] = us_map[\"AFFGEOID\"]\n",
    "del us_map[\"AFFGEOID\"]\n",
    "us_boundaries = pd.merge(us_map,df,on=\"geo_id\")\n",
    "len(us_boundaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## State Data:\n",
    "state_shape = gpd.read_file(\"state_shape/cb_2018_us_state_500k.shp\")\n",
    "len(state_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_shape=state_shape[~state_shape.STATEFP.str.contains(\"02\")]\n",
    "len(state_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = state_shape.STATEFP == \"15\"\n",
    "state_shape[m] = state_shape[m].set_geometry(state_shape[m].translate(54))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = us.states.mapping(\"fips\",\"name\")\n",
    "state = []\n",
    "for i in state_shape[\"STATEFP\"]:\n",
    "    state.append(mapping[i])\n",
    "state_shape[\"state_name\"] = state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Swing Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_geo = alt.InlineData(values = us_boundaries.to_json(), #geopandas to geojson string\n",
    "                       format = alt.DataFormat(property='features',type='json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_geo = alt.InlineData(values = state_shape.to_json(), #geopandas to geojson string\n",
    "                       format = alt.DataFormat(property='features',type='json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = alt.Chart(data_geo).mark_geoshape(strokeWidth=1,stroke='lightgray',strokeOpacity=0.2\n",
    ").encode(\n",
    "    color=alt.Color('properties.swing_dem:Q', scale=alt.Scale(scheme='bluered',domain=[0,1])),\n",
    "    tooltip=['properties.county_name:N','properties.swing_dem:Q','properties.state_name:N']\n",
    ").properties(\n",
    "    width=800,\n",
    "    height=600\n",
    ")\n",
    "outline = alt.Chart(state_geo).mark_geoshape(stroke='black', fillOpacity=0).encode(tooltip=[\"properties.state_name:N\"]).project(\n",
    "    type='albersUsa'\n",
    ").properties(\n",
    "    width=800,\n",
    "    height=600\n",
    ")\n",
    "alt.layer(plot,outline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = alt.Chart(data_geo).mark_geoshape(strokeWidth=1,stroke='lightgray',strokeOpacity=0.2\n",
    ").encode(\n",
    "    color=alt.Color('properties.p_gop_16:Q', scale=alt.Scale(scheme='bluered',domain=[0,1])),\n",
    "    tooltip=['properties.county_name:N','properties.p_gop_16:Q','properties.state:N']\n",
    ").properties(\n",
    "    width=800,\n",
    "    height=600\n",
    ")\n",
    "outline = alt.Chart(state_geo).mark_geoshape(stroke='black', fillOpacity=0).encode(tooltip=[\"properties.state_name:N\"]).project(\n",
    "    type='albersUsa'\n",
    ").properties(\n",
    "    width=800,\n",
    "    height=600\n",
    ")\n",
    "alt.layer(plot,outline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = alt.Chart(data_geo).mark_geoshape(strokeWidth=1,stroke='lightgray',strokeOpacity=0.2\n",
    ").project(type='albersUsa').encode(\n",
    "    color=alt.Color('properties.p_gop_16:Q', scale=alt.Scale(scheme='bluered',domain=[0,1])),\n",
    "    tooltip=['properties.county_name:N','properties.p_gop_16:Q','properties.state:N']\n",
    ").properties(\n",
    "    width=800,\n",
    "    height=600\n",
    ")\n",
    "\n",
    "alt.layer(plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = alt.Chart(data_geo).mark_geoshape(strokeWidth=1,stroke='lightgray',strokeOpacity=0.2\n",
    ").project(type='albersUsa').encode(\n",
    "    color=alt.Color('properties.swing_dem:Q', scale=alt.Scale(scheme='redblue',domain=[-0.15,0.15])),\n",
    "    tooltip=['properties.county_name:N','properties.swing_dem:Q','properties.state:N']\n",
    ").properties(\n",
    "    width=800,\n",
    "    height=600\n",
    ")\n",
    "alt.layer(plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To assess election results, two measures were used; swing from GOP to DEM and a baseline measure of democratic support in the 2016 election.\n",
    "* Looking at the map, the distribution of these two metrics differ between the two maps, suggesting that factors driving each measure may be different and vary greatly between regions. \n",
    "* Outliers: States with deep red and blue bands, indicating that these states swung greater to the right and left respectively. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Investigate the correlation between the two measures:\n",
    "sns.scatterplot(df[\"p_gop_16\"],df[\"swing\"],hue=df[\"state\"],marker=\"x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(df[\"p_gop_16\"],df[\"swing\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Calculating correlation also supports this hypothesis with a c = 0.13647053\n",
    "* Distinct Regional Patterns are also observed, e.g. California strong support for democrats in 2016 election and swung further left, whereas Utah showed strong support for GOP and swung further right in the 2020 election.\n",
    "* Also variation by county, e.g. Texas, counties who showed strong support for democrats in the 2016 election swung further right whereas counties which showed strong support for GOP had a slight swing towards the left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Determine Features which have the same correlation with both measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['total_pop', 'bachelors>', 'veterans',\n",
    "       'white_collar', 'pink_collar', 'blue_collar', 'median_income',\n",
    "       'no_health_insurance', 'p_male', 'p_white', 'p_black', 'p_asian',\n",
    "       'p_latino', 'english_speaking', 'immigrants', 'gen_z', 'gen_y', 'gen_x',\n",
    "       'baby_boomer', 'silent_gen']\n",
    "\n",
    "type(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axes = plt.subplots(ncols=5, nrows=4,figsize=(30,20),sharey=True)\n",
    "for i,f in zip(features,axes.flat):\n",
    "    sns.regplot(df[i],df[\"p_gop_16\"],ax=f,line_kws={\"color\": \"red\"})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axes = plt.subplots(ncols=5, nrows=4,figsize=(30,20),sharey=True)\n",
    "for i,f in zip(features,axes.flat):\n",
    "    sns.regplot(df[i],df[\"swing\"],ax=f,line_kws={\"color\": \"red\"})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Positive Correlations:\n",
    "1. total_pop (cities)\n",
    "2. bachelors> (cities/education)\n",
    "3. White collars (high Income)\n",
    "4. Median Income (high Income)\n",
    "5. p_asian (probably congregates in cities)\n",
    "6. gen_z\n",
    "7. gen_y\n",
    "8. gen_x\n",
    " \n",
    "##### Negative Correlations:\n",
    "1. Blue Collar (poor)\n",
    "2. No Health Insurance (poor)\n",
    "3. immigrants (racism)\n",
    "4. silent_gen (old)\n",
    "5. p-White\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling Voter Probability\n",
    "Now we've found some variables that not only correlate with the share of Remain:Leave vote but also correspond to phenomena that might help explain the vote. We can try to build models to take account of the effects of these variables on the vote.\n",
    "\n",
    "We will generate a multivariate regression model using the variables above that we hypothesise are discriminating. It's worth here quickly revisiting the assumptions of multivariate linear regression:\n",
    "\n",
    "* Linear relationship between expected value of outcome and each explanatory variable\n",
    "* No or limited collinearity of explanatory variables\n",
    "* No (spatial) auto-correlation in residuals \n",
    "* Homoscedasticity (constant variance) in residuals\n",
    "* Normality in distribution of residuals\n",
    "\n",
    "We have already identified linearity in the relationships between our outcome and candidate explanatory variables and we'll discuss the distribution of model residuals shortly. However, we've yet to address the problem of collinearity of explanatory variables. Since we wish to develop a model for *explaining* voter preference, it's important that our model is parsimonious: that is, that we can explain the outcome with as few explanatory variables as possible. Attending to issues of collinearity helps us to do this: we can eliminate variables that effectively represent the same concept. \n",
    "\n",
    "Collinearity can initially be assessed through studying pairwise correlation between each explanatory variable -- the code below allows a matrix of pairwise correlation coefficients to be generated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_variables = ['total_pop', 'bachelors>', 'veterans',\n",
    "       'white_collar', 'pink_collar', 'blue_collar', 'median_income',\n",
    "       'no_health_insurance', 'p_male', 'p_white', 'p_black', 'p_asian',\n",
    "       'p_latino', 'english_speaking', 'immigrants', 'gen_z', 'gen_y', 'gen_x',\n",
    "       'baby_boomer', 'silent_gen']\n",
    "corr_df = df[model_variables]\n",
    "corr_matrix = corr_df.corr(method=\"pearson\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "sns.heatmap(corr_matrix,center=0,cmap=\"RdBu\",annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## VIF\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.tools.tools import add_constant\n",
    "\n",
    "corr_df = add_constant(corr_df)\n",
    "pd.Series([variance_inflation_factor(corr_df.values,i)for i in range(corr_df.shape[1])],index=corr_df.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove:\n",
    "* p_white -p_black\n",
    "* pink collar - blue collar\n",
    "* bachelors - correlated with blue collar, + median income, +asian\n",
    "* baby_boomer, -genz,geny, +silent_gen (old people tend to live together, young people live together)\n",
    "* silent_gen, gen_y\n",
    "\n",
    "\n",
    "* Remove: p_white, pink_collar,blue_collar, p_white,baby_boomer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"bachelors\"] = df[\"bachelors>\"]\n",
    "model_variables = ['bachelors', 'veterans',\n",
    "        'blue_collar',\n",
    "       'no_health_insurance', 'p_male', 'p_white', 'p_asian',\n",
    "       'p_latino', 'english_speaking', 'immigrants', 'gen_z', 'gen_y', 'gen_x']\n",
    "corr_df = df[model_variables]\n",
    "corr_df = add_constant(corr_df)\n",
    "pd.Series([variance_inflation_factor(corr_df.values,i)for i in range(corr_df.shape[1])],index=corr_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extremely low correlation between variables now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Determine Correlation with p_dem_16 and swing\n",
    "import statsmodels.formula.api as smf\n",
    "df[\"bachelors\"] = df[\"bachelors>\"]\n",
    "model_variables = ['bachelors', 'veterans',\n",
    "        'blue_collar',\n",
    "       'no_health_insurance', 'p_white', 'p_asian',\n",
    "       'p_latino', 'english_speaking', 'immigrants', 'gen_z', 'gen_y', 'gen_x']\n",
    "str_model_variables = ' + '.join(model_variables) #Note that we use :1 to remove Leave from the list, as it is the dependent variable\n",
    "lm = smf.ols(formula='p_gop_16 ~ '+str_model_variables, data=df).fit()\n",
    "print(lm.summary())\n",
    "# adding oldergen only increases r-squared by 2 percent\n",
    "# Removing both total population and median income results in a 1.7% drop in R-Squared Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Determine Correlation with p_dem_16 and swing\n",
    "import statsmodels.formula.api as smf\n",
    "df[\"bachelors\"] = df[\"bachelors>\"]\n",
    "model_variables = ['bachelors', 'veterans','blue_collar','p_black', 'p_white','p_asian',\n",
    "        'english_speaking', 'gen_y', 'gen_x']\n",
    "str_model_variables = ' + '.join(model_variables) #Note that we use :1 to remove Leave from the list, as it is the dependent variable\n",
    "lm = smf.ols(formula='swing ~ '+str_model_variables, data=df).fit()\n",
    "print(lm.summary())\n",
    "# Dem factors: 0.424\n",
    "#Remove health_insurance, p_latino,immigrants,gen_z\n",
    "# Addition of Older gen, not substantial\n",
    "#inclusion of both p_black and p_white, results in a 1% increase\n",
    "\n",
    "#model_variables = ['bachelors', 'veterans','blue_collar','p_black', 'p_white','p_asian',\n",
    "#        'english_speaking', 'gen_y', 'gen_x']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results from the OLS summary indicates that both the factors determining p_dem_16 vote is different from what caused the swing in 2020, with more factors being involved in swing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Determine Correlation with p_dem_16 and swing\n",
    "import statsmodels.formula.api as smf\n",
    "df[\"bachelors\"] = df[\"bachelors>\"]\n",
    "model_variables = ['bachelors', 'veterans','blue_collar','p_black', 'p_white','p_asian',\n",
    "        'english_speaking', 'gen_y', 'gen_x']\n",
    "str_model_variables = ' + '.join(model_variables) #Note that we use :1 to remove Leave from the list, as it is the dependent variable\n",
    "lm = smf.ols(formula='p_gop_20 ~ '+str_model_variables, data=df).fit()\n",
    "print(lm.summary())\n",
    "# Using 2016 factors, variables R-Squared = 0.676, explains the 2020 results better than 2016 \n",
    "# Using Swing Variables: 0.629, worse explainor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Linear Regression Model and Plotting resiudlas on map:\n",
    "# Normalise Residuals from -1 to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "def scale(x, out_range=(-1, 1), axis=None):\n",
    "    domain = np.min(x, axis), np.max(x, axis)\n",
    "    y = (x - (domain[1] + domain[0]) / 2) / (domain[1] - domain[0])\n",
    "    return y * (out_range[1] - out_range[0]) + (out_range[1] + out_range[0]) / 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_variables = ['bachelors', 'veterans',\n",
    "        'blue_collar',\n",
    "       'no_health_insurance', 'p_white', 'p_asian',\n",
    "       'p_latino', 'english_speaking', 'immigrants', 'gen_z', 'gen_y', 'gen_x']\n",
    "X = df[model_variables]\n",
    "Y = df[[\"p_gop_16\"]]\n",
    "lr.fit(X,Y)\n",
    "pred = lr.predict(X)\n",
    "# Calculate Residuals\n",
    "df[\"pred_gop_16\"] = pred\n",
    "df[\"resi_gop_16\"] = df[\"p_gop_16\"] - df[\"pred_gop_16\"]\n",
    "df[\"resi_gop_16\"] = scale(df[\"resi_gop_16\"])\n",
    "df[\"resi_gop_16\"].describe()\n",
    "us_boundaries[\"resi_gop_16\"]= df[\"resi_gop_16\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_geo = alt.InlineData(values = us_boundaries.to_json(), #geopandas to geojson string\n",
    "                       format = alt.DataFormat(property='features',type='json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = alt.Chart(data_geo).mark_geoshape(strokeWidth=1,stroke='lightgray',strokeOpacity=0.2\n",
    ").project(type='albersUsa').encode(\n",
    "    color=alt.Color('properties.resi_gop_16:Q', scale=alt.Scale(scheme='redblue',domain=[-1,1])),\n",
    "    tooltip=['properties.county_name:N','properties.resi_gop_16:Q','properties.state:N']\n",
    ").properties(\n",
    "    width=800,\n",
    "    height=600\n",
    ")\n",
    "outline = alt.Chart(state_geo).mark_geoshape(stroke='black', fillOpacity=0).encode(tooltip=[\"properties.state_name:N\"]).project(\n",
    "    type='albersUsa'\n",
    ").properties(\n",
    "    width=800,\n",
    "    height=600\n",
    ")\n",
    "alt.layer(plot,outline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Red means that the model underpredicts the number of dem votes in the area \n",
    "* Blue means the model overpredicts the number of dem votes in the area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_variables = ['veterans','p_asian','p_latino','p_white']\n",
    "X = df[model_variables]\n",
    "Y = df[[\"swing\"]]\n",
    "lr.fit(X,Y)\n",
    "pred = lr.predict(X)\n",
    "# Calculate Residuals\n",
    "df[\"pred_swing\"] = pred\n",
    "df[\"resi_swing\"] = df[\"swing\"] - df[\"pred_swing\"]\n",
    "df[\"resi_swing\"] = scale(df[\"resi_swing\"])\n",
    "df[\"resi_swing\"].describe()\n",
    "us_boundaries[\"resi_swing\"]= df[\"resi_swing\"]\n",
    "\n",
    "data_geo = alt.InlineData(values = us_boundaries.to_json(), #geopandas to geojson string\n",
    "                       format = alt.DataFormat(property='features',type='json'))\n",
    "\n",
    "plot = alt.Chart(data_geo).mark_geoshape(strokeWidth=1,stroke='lightgray',strokeOpacity=0.2\n",
    ").project(type='albersUsa').encode(\n",
    "    color=alt.Color('properties.resi_swing:Q', scale=alt.Scale(scheme='redblue',domain=[-1,1])),\n",
    "    tooltip=['properties.county_name:N','properties.resi_swing:Q','properties.state:N']\n",
    ").properties(\n",
    "    width=800,\n",
    "    height=600\n",
    ")\n",
    "outline = alt.Chart(state_geo).mark_geoshape(stroke='black', fillOpacity=0).encode(tooltip=[\"properties.state_name:N\"]).project(\n",
    "    type='albersUsa'\n",
    ").properties(\n",
    "    width=800,\n",
    "    height=600\n",
    ")\n",
    "alt.layer(plot,outline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Can maybe ask which was the strongest driver of dems winning/ republicans loosing\n",
    "* Was it economic,social, demographic factors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Economic\n",
    "X = ['veterans','white_collar','pink_collar','blue_collar','median_income','no_health_insurance']\n",
    "X = df[X]\n",
    "Y = df[[\"swing\"]]\n",
    "lr.fit(X,Y)\n",
    "pred = lr.predict(X)\n",
    "# Calculate Residuals\n",
    "df[\"pred_swing_e\"] = pred\n",
    "df[\"resi_swing_e\"] = df[\"swing\"] - df[\"pred_swing_e\"]\n",
    "df[\"resi_swing_e\"] = scale(df[\"resi_swing_e\"])\n",
    "df[\"resi_swing_e\"].describe()\n",
    "us_boundaries[\"resi_swing_e\"]= df[\"resi_swing_e\"]\n",
    "\n",
    "data_geo = alt.InlineData(values = us_boundaries.to_json(), #geopandas to geojson string\n",
    "                       format = alt.DataFormat(property='features',type='json'))\n",
    "\n",
    "plot = alt.Chart(data_geo).mark_geoshape(strokeWidth=1,stroke='lightgray',strokeOpacity=0.2\n",
    ").project(type='albersUsa').encode(\n",
    "    color=alt.Color('properties.resi_swing_e:Q', scale=alt.Scale(scheme='redblue',domain=[-1,1])),\n",
    "    tooltip=['properties.county_name:N','properties.resi_swing_e:Q','properties.state:N']\n",
    ").properties(\n",
    "    width=800,\n",
    "    height=600\n",
    ")\n",
    "outline = alt.Chart(state_geo).mark_geoshape(stroke='black', fillOpacity=0).encode(tooltip=[\"properties.state_name:N\"]).project(\n",
    "    type='albersUsa'\n",
    ").properties(\n",
    "    width=800,\n",
    "    height=600\n",
    ")\n",
    "\n",
    "alt.layer(plot,outline)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Demographic\n",
    "X = ['total_pop','p_male','p_white','p_black','p_asian','p_latino','immigrants','gen_z','gen_y','gen_x','baby_boomer','silent_gen']\n",
    "X = df[X]\n",
    "Y = df[[\"swing\"]]\n",
    "lr.fit(X,Y)\n",
    "pred = lr.predict(X)\n",
    "# Calculate Residuals\n",
    "df[\"pred_swing_d\"] = pred\n",
    "df[\"resi_swing_d\"] = df[\"swing\"] - df[\"pred_swing_d\"]\n",
    "df[\"resi_swing_d\"] = scale(df[\"resi_swing_d\"])\n",
    "df[\"resi_swing_d\"].describe()\n",
    "us_boundaries[\"resi_swing_d\"]= df[\"resi_swing_d\"]\n",
    "\n",
    "data_geo = alt.InlineData(values = us_boundaries.to_json(), #geopandas to geojson string\n",
    "                       format = alt.DataFormat(property='features',type='json'))\n",
    "\n",
    "plot = alt.Chart(data_geo).mark_geoshape(strokeWidth=1,stroke='lightgray',strokeOpacity=0.2\n",
    ").project(type='albersUsa').encode(\n",
    "    color=alt.Color('properties.resi_swing_d:Q', scale=alt.Scale(scheme='redblue',domain=[-1,1])),\n",
    "    tooltip=['properties.county_name:N','properties.resi_swing_d:Q','properties.state:N']\n",
    ").properties(\n",
    "    width=800,\n",
    "    height=600\n",
    ")\n",
    "outline = alt.Chart(state_geo).mark_geoshape(stroke='black', fillOpacity=0).encode(tooltip=[\"properties.state_name:N\"]).project(\n",
    "    type='albersUsa'\n",
    ").properties(\n",
    "    width=800,\n",
    "    height=600\n",
    ")\n",
    "\n",
    "alt.layer(plot,outline)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Social\n",
    "X = ['bachelors','english_speaking']\n",
    "X = df[X]\n",
    "Y = df[[\"swing\"]]\n",
    "lr.fit(X,Y)\n",
    "pred = lr.predict(X)\n",
    "# Calculate Residuals\n",
    "df[\"pred_swing_s\"] = pred\n",
    "df[\"resi_swing_s\"] = df[\"swing\"] - df[\"pred_swing_s\"]\n",
    "df[\"resi_swing_s\"] = scale(df[\"resi_swing_s\"])\n",
    "df[\"resi_swing_s\"].describe()\n",
    "us_boundaries[\"resi_swing_s\"]= df[\"resi_swing_s\"]\n",
    "\n",
    "data_geo = alt.InlineData(values = us_boundaries.to_json(), #geopandas to geojson string\n",
    "                       format = alt.DataFormat(property='features',type='json'))\n",
    "\n",
    "plot = alt.Chart(data_geo).mark_geoshape(strokeWidth=1,stroke='lightgray',strokeOpacity=0.2\n",
    ").project(type='albersUsa').encode(\n",
    "    color=alt.Color('properties.resi_swing_s:Q', scale=alt.Scale(scheme='redblue',domain=[-1,1])),\n",
    "    tooltip=['properties.county_name:N','properties.resi_swing_s:Q','properties.state:N']\n",
    ").properties(\n",
    "    width=800,\n",
    "    height=600\n",
    ")\n",
    "outline = alt.Chart(state_geo).mark_geoshape(stroke='black', fillOpacity=0).encode(tooltip=[\"properties.state_name:N\"]).project(\n",
    "    type='albersUsa'\n",
    ").properties(\n",
    "    width=800,\n",
    "    height=600\n",
    ")\n",
    "\n",
    "alt.layer(plot,outline)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing 2016 factor weights to 2020 factor weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2016\n",
    "model_var = ['p_white','pink_collar','bachelors','gen_x','white_collar','veterans','no_health_insurance','english_speaking','p_asian','p_latino','gen_y']\n",
    "X = df[model_var]\n",
    "Y = df[[\"p_gop_16\"]]\n",
    "lr.fit(X,Y)\n",
    "pred = lr.predict(X)\n",
    "# Calculate Residuals\n",
    "df[\"pred_gop_16\"] = pred\n",
    "df[\"resi_gop_16\"] = df[\"p_gop_16\"] - df[\"pred_gop_16\"]\n",
    "df[\"resi_gop_16\"] = scale(df[\"resi_gop_16\"])\n",
    "df[\"resi_gop_16\"].describe()\n",
    "us_boundaries[\"resi_gop_16\"]= df[\"resi_gop_16\"]\n",
    "\n",
    "data_geo = alt.InlineData(values = us_boundaries.to_json(), #geopandas to geojson string\n",
    "                       format = alt.DataFormat(property='features',type='json'))\n",
    "\n",
    "plot = alt.Chart(data_geo).mark_geoshape(strokeWidth=1,stroke='lightgray',strokeOpacity=0.2\n",
    ").project(type='albersUsa').encode(\n",
    "    color=alt.Color('properties.resi_gop_16:Q', scale=alt.Scale(scheme='redblue',domain=[-1,1])),\n",
    "    tooltip=['properties.county_name:N','properties.resi_gop_16:Q','properties.state:N']\n",
    ").properties(\n",
    "    width=800,\n",
    "    height=600\n",
    ")\n",
    "outline = alt.Chart(state_geo).mark_geoshape(stroke='black', fillOpacity=0).encode(tooltip=[\"properties.state_name:N\"]).project(\n",
    "    type='albersUsa'\n",
    ").properties(\n",
    "    width=800,\n",
    "    height=600\n",
    ")\n",
    "coef_16 = dict(zip(model_var,lr.coef_[0]))\n",
    "print(coef_16)\n",
    "alt.layer(plot,outline)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2020\n",
    "model_var = ['p_white','pink_collar','bachelors','gen_x','white_collar','veterans','no_health_insurance','english_speaking','p_asian','p_latino','gen_y']\n",
    "X = df[model_var]\n",
    "Y = df[[\"p_gop_20\"]]\n",
    "lr.fit(X,Y)\n",
    "pred = lr.predict(X)\n",
    "# Calculate Residuals\n",
    "df[\"pred_gop_20\"] = pred\n",
    "df[\"resi_gop_20\"] = df[\"p_gop_20\"] - df[\"pred_gop_20\"]\n",
    "df[\"resi_gop_20\"] = scale(df[\"resi_gop_20\"])\n",
    "df[\"resi_gop_20\"].describe()\n",
    "us_boundaries[\"resi_gop_20\"]= df[\"resi_gop_20\"]\n",
    "\n",
    "data_geo = alt.InlineData(values = us_boundaries.to_json(), #geopandas to geojson string\n",
    "                       format = alt.DataFormat(property='features',type='json'))\n",
    "\n",
    "plot = alt.Chart(data_geo).mark_geoshape(strokeWidth=1,stroke='lightgray',strokeOpacity=0.2\n",
    ").project(type='albersUsa').encode(\n",
    "    color=alt.Color('properties.resi_gop_20:Q', scale=alt.Scale(scheme='redblue',domain=[-1,1])),\n",
    "    tooltip=['properties.county_name:N','properties.resi_gop_20:Q','properties.state:N']\n",
    ").properties(\n",
    "    width=800,\n",
    "    height=600\n",
    ")\n",
    "outline = alt.Chart(state_geo).mark_geoshape(stroke='black', fillOpacity=0).encode(tooltip=[\"properties.state_name:N\"]).project(\n",
    "    type='albersUsa'\n",
    ").properties(\n",
    "    width=800,\n",
    "    height=600\n",
    ")\n",
    "coef_20 = dict(zip(model_var,lr.coef_[0]))\n",
    "print(coef_20)\n",
    "alt.layer(plot,outline)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resi_under_16 = df[df['resi_gop_16']>-0.5] ## Many counties heavily under predicted\n",
    "resi_under_20 = df[df['resi_gop_20']>-0.5] ##Less counties under predicted\n",
    "resi_over_16 = df[df['resi_gop_16']>0.5] ## Many counties heavily under predicted\n",
    "resi_over_20 = df[df['resi_gop_20']>0.5] ##Less counties under predicted\n",
    "\n",
    "#What this indicates is that baseline comparison would be lower therefore factor importance for 2016 should be significantly higher ??\n",
    "\n",
    "\n",
    "print(f'under16: {len(resi_under_16)},under20:{len(resi_under_20)}; over_16:{len(resi_over_16)},over_20:{len(resi_over_20)}')\n",
    "# With immigrants: 16>-0.5: 3040;20>0.5:117\n",
    "# Without Immigrants: 16>-0.5: 3044;20>0.5:106\n",
    "# With baby boomer, silent_gen: 16>-0.5: 3041;20>0.5:52\n",
    "\n",
    "#Similar numbers of over and under predictions above -0.5 and 0.5\n",
    "# under16: 3066,under20:3017; over_16:70,over_20:25\n",
    "# therefore models are similar in predictive capabilities and coefficients can thus be directly compared "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,5))\n",
    "sns.lineplot(list(coef_16.keys()),list(coef_16.values()),label='2016',color=\"r\",marker='o')\n",
    "sns.lineplot(list(coef_20.keys()),list(coef_20.values()),label='2020',color=\"b\",marker='+')\n",
    "plt.xticks( rotation='90')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Education, gen_y, veterans,white collar played a larger role in the 2020 election\n",
    "* Trumps voter base has remained fairly consistent, largely losing followers from veterans,gen_x and a portion of the highly educated.\n",
    "* Largely shows that trumps voter base isnt driven by his policies but mainly by faith/herd behaviour, many of recent policies including intolerant behaviours should have swayed the minority voter base expecting a decrease however that is not see here.\n",
    "* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geographically weighted statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#GWR below requires the \"centroids\" of each geographical area\n",
    "centroids = np.array([[c.x,c.y] for c in us_boundaries.geometry.centroid])\n",
    "\n",
    "#These are all the variables we want to apply geographically-weighted statistics\n",
    "refined_vars=['p_white','pink_collar','bachelors','gen_x','white_collar','veterans','no_health_insurance','english_speaking','p_asian','p_latino','gen_y']\n",
    "coeff_names = ['intercept']\n",
    "map_vars = []\n",
    "for var in refined_vars:\n",
    "    coeff_names.append('coeff_'+var)\n",
    "    map_vars.append('properties.coeff_'+var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mgwr.gwr import GWR, MGWR\n",
    "us_boundaries[\"bachelors\"] = df[\"bachelors\"]\n",
    "#Define GWR model\n",
    "model = GWR(centroids,us_boundaries['p_gop_20'].to_numpy().reshape((-1,1))\n",
    "            ,us_boundaries[refined_vars].to_numpy(),bw=50,kernel='bisquare',fixed=False)\n",
    "gw_results = model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GWR or GWRResult does not calculate geographically-weighted correlation coefficients for all variables\n",
    "#So, this is an adapted version of https://github.com/pysal/mgwr/blob/master/mgwr/gwr.py#L1092\n",
    "def all_corr(results,variables):\n",
    "    \"\"\"\n",
    "    Computes  local correlation coefficients (n, (((p+1)**2) + (p+1) / 2) within a geographically\n",
    "    weighted design matrix\n",
    "    Returns one array with the order and dimensions listed above where n\n",
    "    is the number of locations used as calibrations points and p is the\n",
    "    number of explanatory variables; +1 accounts for the dependent variable.\n",
    "    Local correlation coefficient is not calculated for constant term.\n",
    "    \"\"\"\n",
    "    #print(self.model)\n",
    "    x = results.X\n",
    "    y = results.y\n",
    "    x = np.column_stack((x,y))\n",
    "    w = results.W\n",
    "    nvar = x.shape[1]\n",
    "    nrow = len(w)\n",
    "    if results.model.constant:\n",
    "        ncor = (((nvar - 1)**2 + (nvar - 1)) / 2) - (nvar - 1)\n",
    "        jk = list(combo(range(1, nvar), 2))\n",
    "    else:\n",
    "        ncor = (((nvar)**2 + (nvar)) / 2) - nvar\n",
    "        jk = list(combo(range(nvar), 2))\n",
    "    corr_mat = np.ndarray((nrow, int(ncor)),dtype=dict)\n",
    "    \n",
    "    for i in range(nrow):\n",
    "        wi = w[i]\n",
    "        sw = np.sum(wi)\n",
    "        wi = wi / sw\n",
    "        tag = 0\n",
    "\n",
    "        for j, k in jk:\n",
    "            val = corr(np.cov(x[:, j], x[:, k], aweights=wi))[0][1] \n",
    "            corr_mat[i,tag] = {\"var\": variables[j-1]+\"_\"+variables[k-1], \"var_1\": variables[j-1], \"var_2\": variables[k-1], \"value\": val}\n",
    "            tag = tag + 1\n",
    "            \n",
    "    return corr_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mgwr.diagnostics import corr\n",
    "from itertools import combinations as combo\n",
    "\n",
    "corr_matrix = all_corr(gw_results,refined_vars+['p_gop_20'])\n",
    "#Filter only those correlation coefficients against the Leave vote\n",
    "corr_2 = [{d['var']: d['value'] for d in x if d['var_2'] == 'p_gop_20'} for x in corr_matrix]\n",
    "corr_coeffs = pd.DataFrame.from_records(corr_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if we have what we wanted (all variables correlated with Leave)\n",
    "corr_coeffs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df = pd.merge(us_boundaries,corr_coeffs,left_index=True,right_index=True)\n",
    "map_vars = ['properties.'+v for v in corr_coeffs.columns.values ]\n",
    "corr_geo = alt.InlineData(values = corr_df.to_json(),\n",
    "                       format = alt.DataFormat(property='features',type='json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(corr_coeffs.columns.values)\n",
    "alt.Chart(corr_geo \n",
    ").mark_geoshape(strokeWidth=1,stroke='lightgray',strokeOpacity=0.2\n",
    ").encode(color=alt.Color(alt.repeat('repeat'), type='quantitative', scale=alt.Scale(scheme='purplegreen')),\n",
    "    tooltip=['properties.state_name:N',alt.Tooltip(alt.repeat(\"repeat\"), type=\"quantitative\")],\n",
    ").properties(\n",
    "    projection={'type': 'identity','reflectY': True},\n",
    "    width=175,\n",
    "    height=260,\n",
    ").repeat(map_vars,columns=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "us_boundaries[\"bachelors\"] = df[\"bachelors\"]\n",
    "#Define GWR model\n",
    "model_16 = GWR(centroids,us_boundaries['p_gop_16'].to_numpy().reshape((-1,1))\n",
    "            ,us_boundaries[refined_vars].to_numpy(),bw=50,kernel='bisquare',fixed=False)\n",
    "gw_results = model_16.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = all_corr(gw_results,refined_vars+['p_gop_16'])\n",
    "#Filter only those correlation coefficients against the Leave vote\n",
    "corr_2 = [{d['var']: d['value'] for d in x if d['var_2'] == 'p_gop_16'} for x in corr_matrix]\n",
    "corr_coeffs = pd.DataFrame.from_records(corr_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_coeffs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df = pd.merge(us_boundaries,corr_coeffs,left_index=True,right_index=True)\n",
    "map_vars = ['properties.'+v for v in corr_coeffs.columns.values ]\n",
    "corr_geo = alt.InlineData(values = corr_df.to_json(),\n",
    "                       format = alt.DataFormat(property='features',type='json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(corr_coeffs.columns.values)\n",
    "alt.Chart(corr_geo \n",
    ").mark_geoshape(strokeWidth=1,stroke='lightgray',strokeOpacity=0.2\n",
    ").encode(color=alt.Color(alt.repeat('repeat'), type='quantitative', scale=alt.Scale(scheme='purplegreen')),\n",
    "    tooltip=['properties.state_name:N',alt.Tooltip(alt.repeat(\"repeat\"), type=\"quantitative\")],\n",
    ").properties(\n",
    "    projection={'type': 'identity','reflectY': True},\n",
    "    width=175,\n",
    "    height=260,\n",
    ").repeat(map_vars,columns=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **<font color='red'>GROUP DISCUSSION POINT 5</font>**\n",
    ">\n",
    "> The maps are correlation coefficients for the variables in the order listed above with %leave.\n",
    ">\n",
    "> * Study the maps. Which variables are more regionally distinct?\n",
    "> * Can you offer explanations as to why this might be?\n",
    "\n",
    "\n",
    "Scanning across the maps and making systematic claims about combinations of relationships is challenging. Clustering LAs on their gw-correlation coefficients might help. In the code below, each LA is summarised according to its geographically-weighted correlation coefficient and agglomerative hierarchical cluster analysis (HCA) is used to identify groups of LAs that share *similar combinations of relationship*. LAs are then ‘agglomerated’ into groups iteratively by merging the most similar LAs. This continues until all LAs are merged into a single group. We can evaluate the clustering visually by plotting a dendrogram depicting this agglomeration process, and numerically by considering Average Silhouette Width (ASW) values, calculated at different cuts (number of clusters) of the dendrogram. \n",
    "\n",
    "We won't go into length about the choice of cluster analysis: if two variables are included that represent the same concept, then that concept is given undue weight. Variables were carefully selected by visually inspecting correlation matrices of the geographically-weighted correlation coefficients – similar to the approach for assessing collinearity in regression. The input variables selected via this process are: __Christian, degree-educated, no car, not good health, white.__\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clustering "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Variables selected for use: p_asian,english_speaking, bachelors>,veterans,no_health_insurance\n",
    "* P_asian has similar patterns to white_collar, pink_collar, gen_y\n",
    "* p_latino has weak correlation with gop votes in general\n",
    "* p_white similar to english_speaking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#First we standardise the variables\n",
    "cluster_variables = ['p_asian_p_gop_20','english_speaking_p_gop_20','bachelors_p_gop_20','veterans_p_gop_20','no_health_insurance_p_gop_20' ]\n",
    "scaler = StandardScaler()\n",
    "scaled_coefficients=scaler.fit_transform(corr_coeffs[cluster_variables])\n",
    "scaled_df = pd.DataFrame(scaled_coefficients,columns=corr_coeffs[cluster_variables].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.metrics import silhouette_score,silhouette_samples\n",
    "\n",
    "cluster_results = [None]*12\n",
    "for i in range(2,12): \n",
    "    ac =  AgglomerativeClustering(linkage='ward', n_clusters=i)\n",
    "    cr = ac.fit(scaled_df.values)\n",
    "    cluster_results[i] = cr\n",
    "    print(str(i)+\" clusters. Avg silhouette score:\",silhouette_score(scaled_df.values,cr.labels_))\n",
    "    \n",
    "#With p_asian, best cluster 2 clusters. Avg silhouette score: 0.22718602619530998\n",
    "#Replace asian with white_collar: 2Cluster: worse 0.17893\n",
    "#gen_y 2 clusters. Avg silhouette score: 0.18899976772592417\n",
    "#including both gen_y and asian = 2 clusters. Avg silhouette score: 0.18985285130638524"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hc_result =  cluster_results[2] \n",
    "corr_df['cluster_membership'] = hc_result.labels_\n",
    "corr_coeffs['cluster_membership'] = hc_result.labels_\n",
    "corr_coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sil_scores = pd.DataFrame(\n",
    "    np.column_stack((silhouette_samples(scaled_df.values,hc_result.labels_),hc_result.labels_))\n",
    "    ,columns=['silhouette','cluster_m']).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(sil_scores).mark_bar(\n",
    "        ).encode(\n",
    "            x='silhouette:Q',\n",
    "            y=alt.Y('index:O',sort=alt.SortField(field=\"silhouette\", order='descending'),axis=None),\n",
    "            color=alt.Color('cluster_m:N',scale=alt.Scale(scheme='accent')),\n",
    "            facet='cluster_m:N'\n",
    "        ).properties(width=150,height=250).resolve_scale(y='independent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(alt.InlineData(values = corr_df.to_json(),\n",
    "                       format = alt.DataFormat(property='features',type='json')) \n",
    "         ).mark_geoshape(strokeWidth=1,stroke='lightgray',strokeOpacity=0.2\n",
    "        ).encode(\n",
    "            color=alt.Color('properties.cluster_membership:N',scale=alt.Scale(scheme='accent')),\n",
    "            tooltip=['properties.county_name:N','properties.cluster_membership:N']\n",
    "        ).properties(\n",
    "            projection={'type': 'identity','reflectY': True},\n",
    "            width=800,\n",
    "            height=600,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
